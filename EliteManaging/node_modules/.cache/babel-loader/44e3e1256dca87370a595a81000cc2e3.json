{"ast":null,"code":"var __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n\n    return extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __assign = this && this.__assign || function () {\n  __assign = Object.assign || function (t) {\n    for (var s, i = 1, n = arguments.length; i < n; i++) {\n      s = arguments[i];\n\n      for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n    }\n\n    return t;\n  };\n\n  return __assign.apply(this, arguments);\n};\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function () {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n\n        case 7:\n          op = _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n\n            _.ops.push(op);\n\n            break;\n          }\n\n          if (t[2]) _.ops.pop();\n\n          _.trys.pop();\n\n          continue;\n      }\n\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nimport { Credentials, getAmplifyUserAgent } from '@aws-amplify/core';\nimport Storage from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport { RekognitionClient, SearchFacesByImageCommand, DetectTextCommand, DetectLabelsCommand, DetectFacesCommand, DetectModerationLabelsCommand, RecognizeCelebritiesCommand } from '@aws-sdk/client-rekognition';\nimport { isStorageSource, isFileSource, isBytesSource, isIdentifyCelebrities, isIdentifyFromCollection } from '../types';\nimport { TextractClient, DetectDocumentTextCommand, AnalyzeDocumentCommand } from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport { categorizeRekognitionBlocks, categorizeTextractBlocks } from './IdentifyTextUtils';\n\nvar AmazonAIIdentifyPredictionsProvider =\n/** @class */\nfunction (_super) {\n  __extends(AmazonAIIdentifyPredictionsProvider, _super);\n\n  function AmazonAIIdentifyPredictionsProvider() {\n    return _super.call(this) || this;\n  }\n\n  AmazonAIIdentifyPredictionsProvider.prototype.getProviderName = function () {\n    return 'AmazonAIIdentifyPredictionsProvider';\n  };\n  /**\n   * Verify user input source and converts it into source object readable by Rekognition and Textract.\n   * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n   * @param {IdentifySource} source - User input source that directs to the object user wants\n   * to identify (storage, file, or bytes).\n   * @return {Promise<Image>} - Promise resolving to the converted source object.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.configureSource = function (source) {\n    return new Promise(function (res, rej) {\n      if (isStorageSource(source)) {\n        var storageConfig = {\n          level: source.level,\n          identityId: source.identityId\n        };\n        Storage.get(source.key, storageConfig).then(function (url) {\n          var parser = /https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n          var parsedURL = url.match(parser);\n          if (parsedURL.length < 3) rej('Invalid S3 key was given.');\n          res({\n            S3Object: {\n              Bucket: parsedURL[1],\n              Name: decodeURIComponent(parsedURL[2])\n            }\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isFileSource(source)) {\n        blobToArrayBuffer(source.file).then(function (buffer) {\n          res({\n            Bytes: new Uint8Array(buffer)\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isBytesSource(source)) {\n        var bytes = source.bytes;\n\n        if (bytes instanceof Blob) {\n          blobToArrayBuffer(bytes).then(function (buffer) {\n            res({\n              Bytes: new Uint8Array(buffer)\n            });\n          }).catch(function (err) {\n            return rej(err);\n          });\n        }\n\n        if (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n          res({\n            Bytes: new Uint8Array(bytes)\n          });\n        } // everything else can be directly passed to Rekognition / Textract.\n\n\n        res({\n          Bytes: bytes\n        });\n      } else {\n        rej('Input source is not configured correctly.');\n      }\n    });\n  };\n  /**\n   * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n   * image and converts it into machine-readable text.\n   * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n   * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyText = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, configFormat, inputDocument, err_1, format, featureTypes, textractParam, rekognitionParam, detectTextCommand, rekognitionData, rekognitionResponse, detectDocumentTextCommand, Blocks, err_2, param, analyzeDocumentCommand, Blocks, err_3;\n\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyText, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).format, configFormat = _e === void 0 ? 'PLAIN' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            this.textractClient = new TextractClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            _f.label = 2;\n\n          case 2:\n            _f.trys.push([2, 4,, 5]);\n\n            return [4\n            /*yield*/\n            , this.configureSource(input.text.source)];\n\n          case 3:\n            inputDocument = _f.sent();\n            return [3\n            /*break*/\n            , 5];\n\n          case 4:\n            err_1 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_1)];\n\n          case 5:\n            format = input.text.format || configFormat;\n            featureTypes = [];\n            if (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n            if (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n            if (!(featureTypes.length === 0)) return [3\n            /*break*/\n            , 11];\n            textractParam = {\n              Document: inputDocument\n            };\n            rekognitionParam = {\n              Image: inputDocument\n            };\n            _f.label = 6;\n\n          case 6:\n            _f.trys.push([6, 9,, 10]);\n\n            detectTextCommand = new DetectTextCommand(rekognitionParam);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectTextCommand)];\n\n          case 7:\n            rekognitionData = _f.sent();\n            rekognitionResponse = categorizeRekognitionBlocks(rekognitionData.TextDetections);\n\n            if (rekognitionResponse.text.words.length < 50) {\n              // did not hit the word limit, return the data\n              return [2\n              /*return*/\n              , rekognitionResponse];\n            }\n\n            detectDocumentTextCommand = new DetectDocumentTextCommand(textractParam);\n            return [4\n            /*yield*/\n            , this.textractClient.send(detectDocumentTextCommand)];\n\n          case 8:\n            Blocks = _f.sent().Blocks;\n\n            if (rekognitionData.TextDetections.length > Blocks.length) {\n              return [2\n              /*return*/\n              , rekognitionResponse];\n            }\n\n            return [2\n            /*return*/\n            , categorizeTextractBlocks(Blocks)];\n\n          case 9:\n            err_2 = _f.sent();\n            Promise.reject(err_2);\n            return [3\n            /*break*/\n            , 10];\n\n          case 10:\n            return [3\n            /*break*/\n            , 15];\n\n          case 11:\n            param = {\n              Document: inputDocument,\n              FeatureTypes: featureTypes\n            };\n            _f.label = 12;\n\n          case 12:\n            _f.trys.push([12, 14,, 15]);\n\n            analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n            return [4\n            /*yield*/\n            , this.textractClient.send(analyzeDocumentCommand)];\n\n          case 13:\n            Blocks = _f.sent().Blocks;\n            return [2\n            /*return*/\n            , categorizeTextractBlocks(Blocks)];\n\n          case 14:\n            err_3 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_3)];\n\n          case 15:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Identify instances of real world entities from an image and if it contains unsafe content.\n   * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyLabels = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, type, inputImage_1, param, servicePromises, entityType, err_4;\n\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            _f.trys.push([0, 3,, 4]);\n\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyLabels, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).type, type = _e === void 0 ? 'LABELS' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            return [4\n            /*yield*/\n            , this.configureSource(input.labels.source).then(function (data) {\n              inputImage_1 = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 2:\n            _f.sent();\n\n            param = {\n              Image: inputImage_1\n            };\n            servicePromises = [];\n            entityType = input.labels.type || type;\n\n            if (entityType === 'LABELS' || entityType === 'ALL') {\n              servicePromises.push(this.detectLabels(param));\n            }\n\n            if (entityType === 'UNSAFE' || entityType === 'ALL') {\n              servicePromises.push(this.detectModerationLabels(param));\n            }\n\n            return [2\n            /*return*/\n            , Promise.all(servicePromises).then(function (data) {\n              var identifyResult = {}; // concatenate resolved promises to a single object\n\n              data.forEach(function (val) {\n                identifyResult = __assign(__assign({}, identifyResult), val);\n              });\n              return identifyResult;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 3:\n            err_4 = _f.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_4)];\n\n          case 4:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectLabels and organizes the returned data.\n   * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.detectLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectLabelsCommand, data, detectLabelData, err_5;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n\n            detectLabelsCommand = new DetectLabelsCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectLabelsCommand)];\n\n          case 1:\n            data = _a.sent();\n            if (!data.Labels) return [2\n            /*return*/\n            , {\n              labels: null\n            }]; // no image was detected\n\n            detectLabelData = data.Labels.map(function (val) {\n              var boxes = val.Instances ? val.Instances.map(function (val) {\n                return makeCamelCase(val.BoundingBox);\n              }) : undefined;\n              return {\n                name: val.Name,\n                boundingBoxes: boxes,\n                metadata: {\n                  confidence: val.Confidence,\n                  parents: makeCamelCaseArray(val.Parents)\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              labels: detectLabelData\n            }];\n\n          case 2:\n            err_5 = _a.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_5)];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectModerationLabels and organizes the returned data.\n   * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.detectModerationLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectModerationLabelsCommand, data, err_6;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n\n            detectModerationLabelsCommand = new DetectModerationLabelsCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectModerationLabelsCommand)];\n\n          case 1:\n            data = _a.sent();\n\n            if (data.ModerationLabels.length !== 0) {\n              return [2\n              /*return*/\n              , {\n                unsafe: 'YES'\n              }];\n            } else {\n              return [2\n              /*return*/\n              , {\n                unsafe: 'NO'\n              }];\n            }\n\n            return [3\n            /*break*/\n            , 3];\n\n          case 2:\n            err_6 = _a.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_6)];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\n   * Identify faces within an image that is provided as input, and match faces from a collection\n   * or identify celebrities.\n   * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n   * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n   */\n\n\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyEntities = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, celebrityDetectionEnabled, _e, _f, _g, collectionIdConfig, _h, maxFacesConfig, inputImage, param, recognizeCelebritiesCommand, data, faces, err_7, _j, _k, collectionId, _l, maxFaces, updatedParam, searchFacesByImageCommand, data, faces, err_8, detectFacesCommand, data, faces, err_9;\n\n      var _this = this;\n\n      return __generator(this, function (_m) {\n        switch (_m.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , Credentials.get()];\n\n          case 1:\n            credentials = _m.sent();\n            if (!credentials) return [2\n            /*return*/\n            , Promise.reject('No credentials')];\n            _a = this._config.identifyEntities, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.celebrityDetectionEnabled, celebrityDetectionEnabled = _d === void 0 ? false : _d, _e = _b.defaults, _f = _e === void 0 ? {} : _e, _g = _f.collectionId, collectionIdConfig = _g === void 0 ? '' : _g, _h = _f.maxEntities, maxFacesConfig = _h === void 0 ? 50 : _h; // default arguments\n\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: getAmplifyUserAgent()\n            });\n            return [4\n            /*yield*/\n            , this.configureSource(input.entities.source).then(function (data) {\n              return inputImage = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n\n          case 2:\n            _m.sent();\n\n            param = {\n              Attributes: ['ALL'],\n              Image: inputImage\n            };\n            if (!(isIdentifyCelebrities(input.entities) && input.entities.celebrityDetection)) return [3\n            /*break*/\n            , 7];\n\n            if (!celebrityDetectionEnabled) {\n              return [2\n              /*return*/\n              , Promise.reject('Error: You have to enable celebrity detection first')];\n            }\n\n            _m.label = 3;\n\n          case 3:\n            _m.trys.push([3, 5,, 6]);\n\n            recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(recognizeCelebritiesCommand)];\n\n          case 4:\n            data = _m.sent();\n            faces = data.CelebrityFaces.map(function (celebrity) {\n              return {\n                boundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n                landmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n                metadata: __assign(__assign({}, makeCamelCase(celebrity, ['Id', 'Name', 'Urls'])), {\n                  pose: makeCamelCase(celebrity.Face.Pose)\n                })\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 5:\n            err_7 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_7)];\n\n          case 6:\n            return [3\n            /*break*/\n            , 15];\n\n          case 7:\n            if (!(isIdentifyFromCollection(input.entities) && input.entities.collection)) return [3\n            /*break*/\n            , 12];\n            _j = input.entities, _k = _j.collectionId, collectionId = _k === void 0 ? collectionIdConfig : _k, _l = _j.maxEntities, maxFaces = _l === void 0 ? maxFacesConfig : _l;\n            updatedParam = __assign(__assign({}, param), {\n              CollectionId: collectionId,\n              MaxFaces: maxFaces\n            });\n            _m.label = 8;\n\n          case 8:\n            _m.trys.push([8, 10,, 11]);\n\n            searchFacesByImageCommand = new SearchFacesByImageCommand(updatedParam);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(searchFacesByImageCommand)];\n\n          case 9:\n            data = _m.sent();\n            faces = data.FaceMatches.map(function (val) {\n              return {\n                boundingBox: makeCamelCase(val.Face.BoundingBox),\n                metadata: {\n                  externalImageId: _this.decodeExternalImageId(val.Face.ExternalImageId),\n                  similarity: val.Similarity\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 10:\n            err_8 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_8)];\n\n          case 11:\n            return [3\n            /*break*/\n            , 15];\n\n          case 12:\n            _m.trys.push([12, 14,, 15]);\n\n            detectFacesCommand = new DetectFacesCommand(param);\n            return [4\n            /*yield*/\n            , this.rekognitionClient.send(detectFacesCommand)];\n\n          case 13:\n            data = _m.sent();\n            faces = data.FaceDetails.map(function (detail) {\n              // face attributes keys we want to extract from Rekognition's response\n              var attributeKeys = ['Smile', 'Eyeglasses', 'Sunglasses', 'Gender', 'Beard', 'Mustache', 'EyesOpen', 'MouthOpen'];\n              var faceAttributes = makeCamelCase(detail, attributeKeys);\n\n              if (detail.Emotions) {\n                faceAttributes['emotions'] = detail.Emotions.map(function (emotion) {\n                  return emotion.Type;\n                });\n              }\n\n              return {\n                boundingBox: makeCamelCase(detail.BoundingBox),\n                landmarks: makeCamelCaseArray(detail.Landmarks),\n                ageRange: makeCamelCase(detail.AgeRange),\n                attributes: faceAttributes,\n                metadata: {\n                  confidence: detail.Confidence,\n                  pose: makeCamelCase(detail.Pose)\n                }\n              };\n            });\n            return [2\n            /*return*/\n            , {\n              entities: faces\n            }];\n\n          case 14:\n            err_9 = _m.sent();\n            return [2\n            /*return*/\n            , Promise.reject(err_9)];\n\n          case 15:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  AmazonAIIdentifyPredictionsProvider.prototype.decodeExternalImageId = function (externalImageId) {\n    return ('' + externalImageId).replace(/::/g, '/');\n  };\n\n  return AmazonAIIdentifyPredictionsProvider;\n}(AbstractIdentifyPredictionsProvider);\n\nexport { AmazonAIIdentifyPredictionsProvider };\n/**\n * @deprecated use named import\n */\n\nexport default AmazonAIIdentifyPredictionsProvider;","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,SACCA,WADD,EAGCC,mBAHD,QAIO,mBAJP;AAKA,OAAOC,OAAP,MAAoB,sBAApB;AACA,SAASC,mCAAT,QAAoD,oBAApD;AACA,SACCC,iBADD,EAECC,yBAFD,EAGCC,iBAHD,EAKCC,mBALD,EAOCC,kBAPD,EAQCC,6BARD,EAUCC,2BAVD,QAWO,6BAXP;AAYA,SAMCC,eAND,EAOCC,YAPD,EAQCC,aARD,EAWCC,qBAXD,EAYCC,wBAZD,QAeO,UAfP;AAsBA,SACCC,cADD,EAECC,yBAFD,EAICC,sBAJD,QAMO,0BANP;AAOA,SAASC,aAAT,EAAwBC,kBAAxB,EAA4CC,iBAA5C,QAAqE,SAArE;AACA,SACCC,2BADD,EAECC,wBAFD,QAGO,qBAHP;;AAKA;AAAA;AAAA;EAAyDC;;EAIxD;WACCC,qBAAO;EACP;;EAEDC;IACC,OAAO,qCAAP;EACA,CAFD;EAIA;;;;;;;;;EAOQA,gEAAR,UAAwBC,MAAxB,EAA8C;IAC7C,OAAO,IAAIC,OAAJ,CAAY,UAACC,GAAD,EAAMC,GAAN,EAAS;MAC3B,IAAInB,eAAe,CAACgB,MAAD,CAAnB,EAA6B;QAC5B,IAAMI,aAAa,GAAG;UACrBC,KAAK,EAAEL,MAAM,CAACK,KADO;UAErBC,UAAU,EAAEN,MAAM,CAACM;QAFE,CAAtB;QAIA/B,OAAO,CAACgC,GAAR,CAAYP,MAAM,CAACQ,GAAnB,EAAwBJ,aAAxB,EACEK,IADF,CACO,UAACC,GAAD,EAAY;UACjB,IAAMC,MAAM,GAAG,6EAAf;UACA,IAAMC,SAAS,GAAGF,GAAG,CAACG,KAAJ,CAAUF,MAAV,CAAlB;UACA,IAAIC,SAAS,CAACE,MAAV,GAAmB,CAAvB,EAA0BX,GAAG,CAAC,2BAAD,CAAH;UAC1BD,GAAG,CAAC;YACHa,QAAQ,EAAE;cACTC,MAAM,EAAEJ,SAAS,CAAC,CAAD,CADR;cAETK,IAAI,EAAEC,kBAAkB,CAACN,SAAS,CAAC,CAAD,CAAV;YAFf;UADP,CAAD,CAAH;QAMA,CAXF,EAYEO,KAZF,CAYQ,eAAG;UAAI,UAAG,CAACC,GAAD,CAAH;QAAQ,CAZvB;MAaA,CAlBD,MAkBO,IAAInC,YAAY,CAACe,MAAD,CAAhB,EAA0B;QAChCN,iBAAiB,CAACM,MAAM,CAACqB,IAAR,CAAjB,CACEZ,IADF,CACO,kBAAM;UACXP,GAAG,CAAC;YAAEoB,KAAK,EAAE,IAAIC,UAAJ,CAAeC,MAAf;UAAT,CAAD,CAAH;QACA,CAHF,EAIEL,KAJF,CAIQ,eAAG;UAAI,UAAG,CAACC,GAAD,CAAH;QAAQ,CAJvB;MAKA,CANM,MAMA,IAAIlC,aAAa,CAACc,MAAD,CAAjB,EAA2B;QACjC,IAAMyB,KAAK,GAAGzB,MAAM,CAACyB,KAArB;;QACA,IAAIA,KAAK,YAAYC,IAArB,EAA2B;UAC1BhC,iBAAiB,CAAC+B,KAAD,CAAjB,CACEhB,IADF,CACO,kBAAM;YACXP,GAAG,CAAC;cAAEoB,KAAK,EAAE,IAAIC,UAAJ,CAAeC,MAAf;YAAT,CAAD,CAAH;UACA,CAHF,EAIEL,KAJF,CAIQ,eAAG;YAAI,UAAG,CAACC,GAAD,CAAH;UAAQ,CAJvB;QAKA;;QACD,IAAIK,KAAK,YAAYE,WAAjB,IAAgCF,KAAK,YAAYG,MAArD,EAA6D;UAC5D1B,GAAG,CAAC;YAAEoB,KAAK,EAAE,IAAIC,UAAJ,CAAeE,KAAf;UAAT,CAAD,CAAH;QACA,CAXgC,CAYjC;;;QACAvB,GAAG,CAAC;UAAEoB,KAAK,EAAEG;QAAT,CAAD,CAAH;MACA,CAdM,MAcA;QACNtB,GAAG,CAAC,2CAAD,CAAH;MACA;IACD,CA1CM,CAAP;EA2CA,CA5CO;EA8CR;;;;;;;;EAMgBJ,6DAAhB,UACC8B,KADD,EACyB;;;;;;;YAEJ;YAAA;YAAA,EAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;YAAduB,WAAW,GAAGC,SAAd;YACN,IAAI,CAACD,WAAL,EAAkB;YAAA;YAAA,EAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;YAEjBC,KAIG,KAAKC,OAAL,CAAYC,YAJf,uBAGI,EAHJ,GAGMF,EAHN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,gBAFD,EAEaC,sBAAmC,EAAnC,GAAqCD,EAArC,EAAqCE,MAFlD,EAEqBC,YAAY,mBAAG,OAAH,GAAUF,EAF3C;YAKD,KAAKG,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;cAC9C4D,MAAM,QADwC;cAE9CP,WAAW,aAFmC;cAG9Ca,eAAe,EAAErE,mBAAmB;YAHU,CAAtB,CAAzB;YAKA,KAAKsE,cAAL,GAAsB,IAAIvD,cAAJ,CAAmB;cACxCgD,MAAM,QADkC;cAExCP,WAAW,aAF6B;cAGxCa,eAAe,EAAErE,mBAAmB;YAHI,CAAnB,CAAtB;;;;;;YAQiB;YAAA;YAAA,EAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACiB,IAAN,CAAW9C,MAAhC,CAAN;;;YAAhB+C,aAAa,GAAGhB,SAAhB;;;;;;;YAEA;YAAA;YAAA,EAAO9B,OAAO,CAAC+B,MAAR,CAAegB,KAAf,CAAP;;;YAIKR,MAAM,GAAGX,KAAK,CAACiB,IAAN,CAAWN,MAAX,IAAqBC,YAA9B;YACAQ,YAAY,GAAiB,EAA7B;YACN,IAAIT,MAAM,KAAK,MAAX,IAAqBA,MAAM,KAAK,KAApC,EAA2CS,YAAY,CAACC,IAAb,CAAkB,OAAlB;YAC3C,IAAIV,MAAM,KAAK,OAAX,IAAsBA,MAAM,KAAK,KAArC,EAA4CS,YAAY,CAACC,IAAb,CAAkB,QAAlB;kBAExCD,YAAY,CAACnC,MAAb,KAAwB,IAAxB;YAAA;YAAA;YAMGqC,aAAa,GAAmC;cACrDC,QAAQ,EAAEL;YAD2C,CAAhD;YAGAM,gBAAgB,GAA2B;cAChDC,KAAK,EAAEP;YADyC,CAA3C;;;;;;YAKCQ,iBAAiB,GAAG,IAAI5E,iBAAJ,CAAsB0E,gBAAtB,CAApB;YACkB;YAAA;YAAA,EAAM,KAAKX,iBAAL,CAAuBc,IAAvB,CAC7BD,iBAD6B,CAAN;;;YAAlBE,eAAe,GAAG1B,SAAlB;YAIA2B,mBAAmB,GAAG/D,2BAA2B,CACtD8D,eAAe,CAACE,cADsC,CAAjD;;YAGN,IAAID,mBAAmB,CAACZ,IAApB,CAAyBc,KAAzB,CAA+B9C,MAA/B,GAAwC,EAA5C,EAAgD;cAC/C;cACA;cAAA;cAAA,EAAO4C,mBAAP;YACA;;YAEKG,yBAAyB,GAAG,IAAIvE,yBAAJ,CACjC6D,aADiC,CAA5B;YAIa;YAAA;YAAA,EAAM,KAAKP,cAAL,CAAoBY,IAApB,CACxBK,yBADwB,CAAN;;;YAAXC,MAAM,GAAK/B,UAElB+B,MAFO;;YAIR,IAAIL,eAAe,CAACE,cAAhB,CAA+B7C,MAA/B,GAAwCgD,MAAM,CAAChD,MAAnD,EAA2D;cAC1D;cAAA;cAAA,EAAO4C,mBAAP;YACA;;YAED;YAAA;YAAA,EAAO9D,wBAAwB,CAACkE,MAAD,CAA/B;;;;YAEA7D,OAAO,CAAC+B,MAAR,CAAe+B,KAAf;;;;;;;;;;;YAGKC,KAAK,GAAgC;cAC1CZ,QAAQ,EAAEL,aADgC;cAE1CkB,YAAY,EAAEhB;YAF4B,CAArC;;;;;;YAMCiB,sBAAsB,GAAG,IAAI3E,sBAAJ,CAA2ByE,KAA3B,CAAzB;YACa;YAAA;YAAA,EAAM,KAAKpB,cAAL,CAAoBY,IAApB,CACxBU,sBADwB,CAAN;;;YAAXJ,MAAM,GAAK/B,UAElB+B,MAFO;YAGR;YAAA;YAAA,EAAOlE,wBAAwB,CAACkE,MAAD,CAA/B;;;;YAEA;YAAA;YAAA,EAAO7D,OAAO,CAAC+B,MAAR,CAAemC,KAAf,CAAP;;;;;;;;;EAGF,CA9Fe;EAgGhB;;;;;;;EAKgBpE,+DAAhB,UACC8B,KADD,EAC2B;;;;;;;;;YAGL;YAAA;YAAA,EAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;YAAduB,WAAW,GAAGC,SAAd;YACN,IAAI,CAACD,WAAL,EAAkB;YAAA;YAAA,EAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;YAEjBC,KAIG,KAAKC,OAAL,CAAYkC,cAJf,uBAGI,EAHJ,GAGMnC,EAHN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,gBAFD,EAEaC,sBAAoB,EAApB,GAAsBD,EAAtB,EAAsB+B,IAFnC,EAEaA,IAAI,mBAAG,QAAH,GAAW9B,EAF5B;YAKD,KAAKG,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;cAC9C4D,MAAM,QADwC;cAE9CP,WAAW,aAFmC;cAG9Ca,eAAe,EAAErE,mBAAmB;YAHU,CAAtB,CAAzB;YAMA;YAAA;YAAA,EAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACyC,MAAN,CAAatE,MAAlC,EACJS,IADI,CACC,gBAAI;cACT8D,YAAU,GAAGC,IAAb;YACA,CAHI,EAIJrD,KAJI,CAIE,eAAG;cACT,OAAOlB,OAAO,CAAC+B,MAAR,CAAeZ,GAAf,CAAP;YACA,CANI,CAAN;;;YAAAW;;YAOMiC,KAAK,GAAG;cAAEV,KAAK,EAAEiB;YAAT,CAAR;YACAE,eAAe,GAAG,EAAlB;YAGAC,UAAU,GAAG7C,KAAK,CAACyC,MAAN,CAAaD,IAAb,IAAqBA,IAAlC;;YACN,IAAIK,UAAU,KAAK,QAAf,IAA2BA,UAAU,KAAK,KAA9C,EAAqD;cACpDD,eAAe,CAACvB,IAAhB,CAAqB,KAAKyB,YAAL,CAAkBX,KAAlB,CAArB;YACA;;YACD,IAAIU,UAAU,KAAK,QAAf,IAA2BA,UAAU,KAAK,KAA9C,EAAqD;cACpDD,eAAe,CAACvB,IAAhB,CAAqB,KAAK0B,sBAAL,CAA4BZ,KAA5B,CAArB;YACA;;YAED;YAAA;YAAA,EAAO/D,OAAO,CAAC4E,GAAR,CAAYJ,eAAZ,EACLhE,IADK,CACA,gBAAI;cACT,IAAIqE,cAAc,GAAyB,EAA3C,CADS,CAET;;cACAN,IAAI,CAACO,OAAL,CAAa,eAAG;gBACfD,cAAc,yBAAQA,cAAR,GAA2BE,GAA3B,CAAd;cACA,CAFD;cAGA,OAAOF,cAAP;YACA,CARK,EASL3D,KATK,CASC,eAAG;cAAI,cAAO,CAACa,MAAR,CAAeZ,GAAf;YAAmB,CAT3B,CAAP;;;;YAWA;YAAA;YAAA,EAAOnB,OAAO,CAAC+B,MAAR,CAAeiD,KAAf,CAAP;;;;;;;;;EAED,CAlDe;EAoDhB;;;;;;;EAKclF,6DAAd,UACCiE,KADD,EACgC;;;;;;;;YAGxBkB,mBAAmB,GAAG,IAAItG,mBAAJ,CAAwBoF,KAAxB,CAAtB;YACO;YAAA;YAAA,EAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAA4B0B,mBAA5B,CAAN;;;YAAPV,IAAI,GAAGvC,SAAP;YACN,IAAI,CAACuC,IAAI,CAACW,MAAV,EAAkB;YAAA;YAAA,EAAO;cAAEb,MAAM,EAAE;YAAV,CAAP,GAAyB;;YACrCc,eAAe,GAAGZ,IAAI,CAACW,MAAL,CAAYE,GAAZ,CAAgB,eAAG;cAC1C,IAAMC,KAAK,GAAGN,GAAG,CAACO,SAAJ,GACXP,GAAG,CAACO,SAAJ,CAAcF,GAAd,CAAkB,eAAG;gBAAI,oBAAa,CAACL,GAAG,CAACQ,WAAL,CAAb;cAA8B,CAAvD,CADW,GAEXC,SAFH;cAGA,OAAO;gBACNC,IAAI,EAAEV,GAAG,CAAC/D,IADJ;gBAEN0E,aAAa,EAAEL,KAFT;gBAGNM,QAAQ,EAAE;kBACTC,UAAU,EAAEb,GAAG,CAACc,UADP;kBAETC,OAAO,EAAEtG,kBAAkB,CAACuF,GAAG,CAACgB,OAAL;gBAFlB;cAHJ,CAAP;YAQA,CAZuB,CAAlB;YAaN;YAAA;YAAA,EAAO;cAAE1B,MAAM,EAAEc;YAAV,CAAP;;;;YAEA;YAAA;YAAA,EAAOnF,OAAO,CAAC+B,MAAR,CAAeiE,KAAf,CAAP;;;;;;;;;EAED,CAxBa;EA0Bd;;;;;;;EAKclG,uEAAd,UACCiE,KADD,EAC0C;;;;;;;;YAGlCkC,6BAA6B,GAAG,IAAIpH,6BAAJ,CACrCkF,KADqC,CAAhC;YAGO;YAAA;YAAA,EAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAClB0C,6BADkB,CAAN;;;YAAP1B,IAAI,GAAGvC,SAAP;;YAGN,IAAIuC,IAAI,CAAC2B,gBAAL,CAAsBrF,MAAtB,KAAiC,CAArC,EAAwC;cACvC;cAAA;cAAA,EAAO;gBAAEsF,MAAM,EAAE;cAAV,CAAP;YACA,CAFD,MAEO;cACN;cAAA;cAAA,EAAO;gBAAEA,MAAM,EAAE;cAAV,CAAP;YACA;;;;;;;;YAED;YAAA;YAAA,EAAOnG,OAAO,CAAC+B,MAAR,CAAeqE,KAAf,CAAP;;;;;;;;;EAED,CAlBa;EAoBd;;;;;;;;EAMgBtG,iEAAhB,UACC8B,KADD,EAC6B;;;;;;;;;YAER;YAAA;YAAA,EAAMxD,WAAW,CAACkC,GAAZ,EAAN;;;YAAduB,WAAW,GAAGwE,SAAd;YACN,IAAI,CAACxE,WAAL,EAAkB;YAAA;YAAA,EAAO7B,OAAO,CAAC+B,MAAR,CAAe,gBAAf,CAAP;YAEjBC,KAQG,KAAKC,OAAL,CAAYqE,gBARf,uBAOI,EAPJ,GAOMtE,EAPN,EACCG,cADD,EACCC,MAAM,mBAAG,EAAH,GAAKD,EADZ,EAECE,iCAFD,EAECkE,yBAAyB,mBAAG,KAAH,GAAQlE,EAFlC,EAGCC,gBAHD,EAGCR,qBAGI,EAHJ,GAGMQ,EANP,EAIEkE,oBAJF,EAIgBC,kBAAkB,mBAAG,EAAH,GAAKD,EAJvC,EAKEE,mBALF,EAKeC,cAAc,mBAAG,EAAH,GAAKD,EALlC,EASD;;YAEA,KAAKjE,iBAAL,GAAyB,IAAIjE,iBAAJ,CAAsB;cAC9C4D,MAAM,QADwC;cAE9CP,WAAW,aAFmC;cAG9Ca,eAAe,EAAErE,mBAAmB;YAHU,CAAtB,CAAzB;YAMA;YAAA;YAAA,EAAM,KAAKuE,eAAL,CAAqBhB,KAAK,CAACgF,QAAN,CAAe7G,MAApC,EACJS,IADI,CACC,gBAAI;cAAI,OAACqG,UAAU,GAAGtC,IAAd;YAAmB,CAD5B,EAEJrD,KAFI,CAEE,eAAG;cACT,OAAOlB,OAAO,CAAC+B,MAAR,CAAeZ,GAAf,CAAP;YACA,CAJI,CAAN;;;YAAAkF;;YAMMtC,KAAK,GAAG;cAAE+C,UAAU,EAAE,CAAC,KAAD,CAAd;cAAuBzD,KAAK,EAAEwD;YAA9B,CAAR;kBAGL3H,qBAAqB,CAAC0C,KAAK,CAACgF,QAAP,CAArB,IACAhF,KAAK,CAACgF,QAAN,CAAeG,qBADf;YAAA;YAAA;;YAGA,IAAI,CAACR,yBAAL,EAAgC;cAC/B;cAAA;cAAA,EAAOvG,OAAO,CAAC+B,MAAR,CACN,qDADM,CAAP;YAGA;;;;;;;YAEMiF,2BAA2B,GAAG,IAAIlI,2BAAJ,CACnCiF,KADmC,CAA9B;YAGO;YAAA;YAAA,EAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAClByD,2BADkB,CAAN;;;YAAPzC,IAAI,GAAG8B,SAAP;YAGAY,KAAK,GAAG1C,IAAI,CAAC2C,cAAL,CAAoB9B,GAApB,CAAwB,qBAAS;cAC9C,OAAO;gBACN+B,WAAW,EAAE5H,aAAa,CAAC6H,SAAS,CAACC,IAAV,CAAe9B,WAAhB,CADpB;gBAEN+B,SAAS,EAAE9H,kBAAkB,CAAC4H,SAAS,CAACC,IAAV,CAAeE,SAAhB,CAFvB;gBAGN5B,QAAQ,wBACJpG,aAAa,CAAC6H,SAAD,EAAY,CAAC,IAAD,EAAO,MAAP,EAAe,MAAf,CAAZ,CADT,GAC4C;kBACnDI,IAAI,EAAEjI,aAAa,CAAC6H,SAAS,CAACC,IAAV,CAAeI,IAAhB;gBADgC,CAD5C;cAHF,CAAP;YAQA,CATa,CAAR;YAUN;YAAA;YAAA,EAAO;cAAEb,QAAQ,EAAEK;YAAZ,CAAP;;;;YAEA;YAAA;YAAA,EAAOjH,OAAO,CAAC+B,MAAR,CAAe2F,KAAf,CAAP;;;;;;;;kBAGDvI,wBAAwB,CAACyC,KAAK,CAACgF,QAAP,CAAxB,IACAhF,KAAK,CAACgF,QAAN,CAAee,aADf;YAAA;YAAA;YAGMC,KAGFhG,KAAK,CAACgF,QAHJ,EACLiB,oBADK,EACLC,YAAY,mBAAGrB,kBAAH,GAAqBoB,EAD5B,EAELE,mBAFK,EAEQC,QAAQ,mBAAGrB,cAAH,GAAiBoB,EAFjC;YAKAE,YAAY,yBACdlE,KADc,GACT;cACRmE,YAAY,EAAEJ,YADN;cAERK,QAAQ,EAAEH;YAFF,CADS,CAAZ;;;;;;YAMCI,yBAAyB,GAAG,IAAI3J,yBAAJ,CACjCwJ,YADiC,CAA5B;YAGO;YAAA;YAAA,EAAM,KAAKxF,iBAAL,CAAuBc,IAAvB,CAClB6E,yBADkB,CAAN;;;YAAP7D,IAAI,GAAG8B,SAAP;YAGAY,KAAK,GAAG1C,IAAI,CAAC8D,WAAL,CAAiBjD,GAAjB,CAAqB,eAAG;cACrC,OAAO;gBACN+B,WAAW,EAAE5H,aAAa,CAACwF,GAAG,CAACsC,IAAJ,CAAS9B,WAAV,CADpB;gBAENI,QAAQ,EAAE;kBACT2C,eAAe,EAAEC,KAAI,CAACC,qBAAL,CAChBzD,GAAG,CAACsC,IAAJ,CAASoB,eADO,CADR;kBAITC,UAAU,EAAE3D,GAAG,CAAC4D;gBAJP;cAFJ,CAAP;YASA,CAVa,CAAR;YAWN;YAAA;YAAA,EAAO;cAAE/B,QAAQ,EAAEK;YAAZ,CAAP;;;;YAEA;YAAA;YAAA,EAAOjH,OAAO,CAAC+B,MAAR,CAAe6G,KAAf,CAAP;;;;;;;;;;YAIMC,kBAAkB,GAAG,IAAIjK,kBAAJ,CAAuBmF,KAAvB,CAArB;YACO;YAAA;YAAA,EAAM,KAAKtB,iBAAL,CAAuBc,IAAvB,CAA4BsF,kBAA5B,CAAN;;;YAAPtE,IAAI,GAAG8B,SAAP;YACAY,KAAK,GAAG1C,IAAI,CAACuE,WAAL,CAAiB1D,GAAjB,CAAqB,kBAAM;cACxC;cACA,IAAM2D,aAAa,GAAG,CACrB,OADqB,EAErB,YAFqB,EAGrB,YAHqB,EAIrB,QAJqB,EAKrB,OALqB,EAMrB,UANqB,EAOrB,UAPqB,EAQrB,WARqB,CAAtB;cAUA,IAAMC,cAAc,GAAGzJ,aAAa,CAAC0J,MAAD,EAASF,aAAT,CAApC;;cACA,IAAIE,MAAM,CAACC,QAAX,EAAqB;gBACpBF,cAAc,CAAC,UAAD,CAAd,GAA6BC,MAAM,CAACC,QAAP,CAAgB9D,GAAhB,CAC5B,mBAAO;kBAAI,cAAO,CAAC+D,IAAR;gBAAY,CADK,CAA7B;cAGA;;cACD,OAAO;gBACNhC,WAAW,EAAE5H,aAAa,CAAC0J,MAAM,CAAC1D,WAAR,CADpB;gBAEN+B,SAAS,EAAE9H,kBAAkB,CAACyJ,MAAM,CAAC1B,SAAR,CAFvB;gBAGN6B,QAAQ,EAAE7J,aAAa,CAAC0J,MAAM,CAACI,QAAR,CAHjB;gBAINC,UAAU,EAAEN,cAJN;gBAKNrD,QAAQ,EAAE;kBACTC,UAAU,EAAEqD,MAAM,CAACpD,UADV;kBAET2B,IAAI,EAAEjI,aAAa,CAAC0J,MAAM,CAACxB,IAAR;gBAFV;cALJ,CAAP;YAUA,CA5Ba,CAAR;YA6BN;YAAA;YAAA,EAAO;cAAEb,QAAQ,EAAEK;YAAZ,CAAP;;;;YAEA;YAAA;YAAA,EAAOjH,OAAO,CAAC+B,MAAR,CAAewH,KAAf,CAAP;;;;;;;;;EAGF,CAvIe;;EAyIRzJ,sEAAR,UAA8BwI,eAA9B,EAAqD;IACpD,OAAO,CAAC,KAAKA,eAAN,EAAuBkB,OAAvB,CAA+B,KAA/B,EAAsC,GAAtC,CAAP;EACA,CAFO;;EAGT;AAAC,CA1aD,CAAyDjL,mCAAzD;;;AA4aA;;;;AAGA,eAAeuB,mCAAf","names":["Credentials","getAmplifyUserAgent","Storage","AbstractIdentifyPredictionsProvider","RekognitionClient","SearchFacesByImageCommand","DetectTextCommand","DetectLabelsCommand","DetectFacesCommand","DetectModerationLabelsCommand","RecognizeCelebritiesCommand","isStorageSource","isFileSource","isBytesSource","isIdentifyCelebrities","isIdentifyFromCollection","TextractClient","DetectDocumentTextCommand","AnalyzeDocumentCommand","makeCamelCase","makeCamelCaseArray","blobToArrayBuffer","categorizeRekognitionBlocks","categorizeTextractBlocks","__extends","_super","AmazonAIIdentifyPredictionsProvider","source","Promise","res","rej","storageConfig","level","identityId","get","key","then","url","parser","parsedURL","match","length","S3Object","Bucket","Name","decodeURIComponent","catch","err","file","Bytes","Uint8Array","buffer","bytes","Blob","ArrayBuffer","Buffer","input","credentials","_f","reject","_a","_config","identifyText","_c","region","_d","_e","format","configFormat","rekognitionClient","customUserAgent","textractClient","configureSource","text","inputDocument","err_1","featureTypes","push","textractParam","Document","rekognitionParam","Image","detectTextCommand","send","rekognitionData","rekognitionResponse","TextDetections","words","detectDocumentTextCommand","Blocks","err_2","param","FeatureTypes","analyzeDocumentCommand","err_3","identifyLabels","type","labels","inputImage_1","data","servicePromises","entityType","detectLabels","detectModerationLabels","all","identifyResult","forEach","val","err_4","detectLabelsCommand","Labels","detectLabelData","map","boxes","Instances","BoundingBox","undefined","name","boundingBoxes","metadata","confidence","Confidence","parents","Parents","err_5","detectModerationLabelsCommand","ModerationLabels","unsafe","err_6","_m","identifyEntities","celebrityDetectionEnabled","_g","collectionIdConfig","_h","maxFacesConfig","entities","inputImage","Attributes","celebrityDetection","recognizeCelebritiesCommand","faces","CelebrityFaces","boundingBox","celebrity","Face","landmarks","Landmarks","pose","Pose","err_7","collection","_j","_k","collectionId","_l","maxFaces","updatedParam","CollectionId","MaxFaces","searchFacesByImageCommand","FaceMatches","externalImageId","_this","decodeExternalImageId","ExternalImageId","similarity","Similarity","err_8","detectFacesCommand","FaceDetails","attributeKeys","faceAttributes","detail","Emotions","Type","ageRange","AgeRange","attributes","err_9","replace"],"sources":["C:\\Users\\jacob\\OneDrive\\College\\Freshman_2021-2022\\Summer_2022\\COM4570H\\newcrm\\new-crm\\node_modules\\@aws-amplify\\predictions\\src\\Providers\\AmazonAIIdentifyPredictionsProvider.ts"],"sourcesContent":["import {\n\tCredentials,\n\tConsoleLogger as Logger,\n\tgetAmplifyUserAgent,\n} from '@aws-amplify/core';\nimport Storage from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport {\n\tRekognitionClient,\n\tSearchFacesByImageCommand,\n\tDetectTextCommand,\n\tDetectTextCommandInput,\n\tDetectLabelsCommand,\n\tDetectLabelsCommandInput,\n\tDetectFacesCommand,\n\tDetectModerationLabelsCommand,\n\tDetectModerationLabelsCommandInput,\n\tRecognizeCelebritiesCommand,\n} from '@aws-sdk/client-rekognition';\nimport {\n\tIdentifyLabelsInput,\n\tIdentifyLabelsOutput,\n\tIdentifySource,\n\tIdentifyEntitiesInput,\n\tIdentifyEntitiesOutput,\n\tisStorageSource,\n\tisFileSource,\n\tisBytesSource,\n\tIdentifyTextInput,\n\tIdentifyTextOutput,\n\tisIdentifyCelebrities,\n\tisIdentifyFromCollection,\n\tIdentifyFromCollection,\n\tFeatureTypes,\n} from '../types';\nimport {\n\tImage,\n\tDocument,\n\tTextDetectionList,\n\tBlockList,\n} from '../types/AWSTypes';\nimport {\n\tTextractClient,\n\tDetectDocumentTextCommand,\n\tDetectDocumentTextCommandInput,\n\tAnalyzeDocumentCommand,\n\tAnalyzeDocumentCommandInput,\n} from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport {\n\tcategorizeRekognitionBlocks,\n\tcategorizeTextractBlocks,\n} from './IdentifyTextUtils';\n\nexport class AmazonAIIdentifyPredictionsProvider extends AbstractIdentifyPredictionsProvider {\n\tprivate rekognitionClient: RekognitionClient;\n\tprivate textractClient: TextractClient;\n\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetProviderName() {\n\t\treturn 'AmazonAIIdentifyPredictionsProvider';\n\t}\n\n\t/**\n\t * Verify user input source and converts it into source object readable by Rekognition and Textract.\n\t * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n\t * @param {IdentifySource} source - User input source that directs to the object user wants\n\t * to identify (storage, file, or bytes).\n\t * @return {Promise<Image>} - Promise resolving to the converted source object.\n\t */\n\tprivate configureSource(source: IdentifySource): Promise<Image> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tif (isStorageSource(source)) {\n\t\t\t\tconst storageConfig = {\n\t\t\t\t\tlevel: source.level,\n\t\t\t\t\tidentityId: source.identityId,\n\t\t\t\t};\n\t\t\t\tStorage.get(source.key, storageConfig)\n\t\t\t\t\t.then((url: string) => {\n\t\t\t\t\t\tconst parser = /https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n\t\t\t\t\t\tconst parsedURL = url.match(parser);\n\t\t\t\t\t\tif (parsedURL.length < 3) rej('Invalid S3 key was given.');\n\t\t\t\t\t\tres({\n\t\t\t\t\t\t\tS3Object: {\n\t\t\t\t\t\t\t\tBucket: parsedURL[1],\n\t\t\t\t\t\t\t\tName: decodeURIComponent(parsedURL[2]),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t});\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isFileSource(source)) {\n\t\t\t\tblobToArrayBuffer(source.file)\n\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isBytesSource(source)) {\n\t\t\t\tconst bytes = source.bytes;\n\t\t\t\tif (bytes instanceof Blob) {\n\t\t\t\t\tblobToArrayBuffer(bytes)\n\t\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t\t})\n\t\t\t\t\t\t.catch(err => rej(err));\n\t\t\t\t}\n\t\t\t\tif (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n\t\t\t\t\tres({ Bytes: new Uint8Array(bytes) } as Image);\n\t\t\t\t}\n\t\t\t\t// everything else can be directly passed to Rekognition / Textract.\n\t\t\t\tres({ Bytes: bytes } as Image);\n\t\t\t} else {\n\t\t\t\trej('Input source is not configured correctly.');\n\t\t\t}\n\t\t});\n\t}\n\n\t/**\n\t * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n\t * image and converts it into machine-readable text.\n\t * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n\t * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n\t */\n\tprotected async identifyText(\n\t\tinput: IdentifyTextInput\n\t): Promise<IdentifyTextOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyText: {\n\t\t\t\tregion = '',\n\t\t\t\tdefaults: { format: configFormat = 'PLAIN' } = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tthis.textractClient = new TextractClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tlet inputDocument: Document;\n\n\t\ttry {\n\t\t\tinputDocument = await this.configureSource(input.text.source);\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\n\t\t// get default value if format isn't specified in the input.\n\t\tconst format = input.text.format || configFormat;\n\t\tconst featureTypes: FeatureTypes = []; // structures we want to analyze (e.g. [TABLES, FORMS]).\n\t\tif (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n\t\tif (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n\n\t\tif (featureTypes.length === 0) {\n\t\t\t/**\n\t\t\t * Empty featureTypes indicates that we will identify plain text. We will use rekognition (suitable\n\t\t\t * for everyday images but has 50 word limit) first and see if reaches its word limit. If it does, then\n\t\t\t * we call textract and use the data that identify more words.\n\t\t\t */\n\t\t\tconst textractParam: DetectDocumentTextCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t};\n\t\t\tconst rekognitionParam: DetectTextCommandInput = {\n\t\t\t\tImage: inputDocument,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst detectTextCommand = new DetectTextCommand(rekognitionParam);\n\t\t\t\tconst rekognitionData = await this.rekognitionClient.send(\n\t\t\t\t\tdetectTextCommand\n\t\t\t\t);\n\n\t\t\t\tconst rekognitionResponse = categorizeRekognitionBlocks(\n\t\t\t\t\trekognitionData.TextDetections as TextDetectionList\n\t\t\t\t);\n\t\t\t\tif (rekognitionResponse.text.words.length < 50) {\n\t\t\t\t\t// did not hit the word limit, return the data\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\tconst detectDocumentTextCommand = new DetectDocumentTextCommand(\n\t\t\t\t\ttextractParam\n\t\t\t\t);\n\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tdetectDocumentTextCommand\n\t\t\t\t);\n\n\t\t\t\tif (rekognitionData.TextDetections.length > Blocks.length) {\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\tPromise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\tconst param: AnalyzeDocumentCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t\tFeatureTypes: featureTypes,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tanalyzeDocumentCommand\n\t\t\t\t);\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Identify instances of real world entities from an image and if it contains unsafe content.\n\t * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n\t */\n\tprotected async identifyLabels(\n\t\tinput: IdentifyLabelsInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return Promise.reject('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyLabels: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tdefaults: { type = 'LABELS' } = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\t\tregion,\n\t\t\t\tcredentials,\n\t\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t\t});\n\t\t\tlet inputImage: Image;\n\t\t\tawait this.configureSource(input.labels.source)\n\t\t\t\t.then(data => {\n\t\t\t\t\tinputImage = data;\n\t\t\t\t})\n\t\t\t\t.catch(err => {\n\t\t\t\t\treturn Promise.reject(err);\n\t\t\t\t});\n\t\t\tconst param = { Image: inputImage };\n\t\t\tconst servicePromises = [];\n\n\t\t\t// get default argument\n\t\t\tconst entityType = input.labels.type || type;\n\t\t\tif (entityType === 'LABELS' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectLabels(param));\n\t\t\t}\n\t\t\tif (entityType === 'UNSAFE' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectModerationLabels(param));\n\t\t\t}\n\n\t\t\treturn Promise.all(servicePromises)\n\t\t\t\t.then(data => {\n\t\t\t\t\tlet identifyResult: IdentifyLabelsOutput = {};\n\t\t\t\t\t// concatenate resolved promises to a single object\n\t\t\t\t\tdata.forEach(val => {\n\t\t\t\t\t\tidentifyResult = { ...identifyResult, ...val };\n\t\t\t\t\t});\n\t\t\t\t\treturn identifyResult;\n\t\t\t\t})\n\t\t\t\t.catch(err => Promise.reject(err));\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectLabels and organizes the returned data.\n\t * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n\t */\n\tprivate async detectLabels(\n\t\tparam: DetectLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectLabelsCommand = new DetectLabelsCommand(param);\n\t\t\tconst data = await this.rekognitionClient.send(detectLabelsCommand);\n\t\t\tif (!data.Labels) return { labels: null }; // no image was detected\n\t\t\tconst detectLabelData = data.Labels.map(val => {\n\t\t\t\tconst boxes = val.Instances\n\t\t\t\t\t? val.Instances.map(val => makeCamelCase(val.BoundingBox))\n\t\t\t\t\t: undefined;\n\t\t\t\treturn {\n\t\t\t\t\tname: val.Name,\n\t\t\t\t\tboundingBoxes: boxes,\n\t\t\t\t\tmetadata: {\n\t\t\t\t\t\tconfidence: val.Confidence,\n\t\t\t\t\t\tparents: makeCamelCaseArray(val.Parents),\n\t\t\t\t\t},\n\t\t\t\t};\n\t\t\t});\n\t\t\treturn { labels: detectLabelData };\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectModerationLabels and organizes the returned data.\n\t * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n\t */\n\tprivate async detectModerationLabels(\n\t\tparam: DetectModerationLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectModerationLabelsCommand = new DetectModerationLabelsCommand(\n\t\t\t\tparam\n\t\t\t);\n\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\tdetectModerationLabelsCommand\n\t\t\t);\n\t\t\tif (data.ModerationLabels.length !== 0) {\n\t\t\t\treturn { unsafe: 'YES' };\n\t\t\t} else {\n\t\t\t\treturn { unsafe: 'NO' };\n\t\t\t}\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Identify faces within an image that is provided as input, and match faces from a collection\n\t * or identify celebrities.\n\t * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n\t * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n\t */\n\tprotected async identifyEntities(\n\t\tinput: IdentifyEntitiesInput\n\t): Promise<IdentifyEntitiesOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyEntities: {\n\t\t\t\tregion = '',\n\t\t\t\tcelebrityDetectionEnabled = false,\n\t\t\t\tdefaults: {\n\t\t\t\t\tcollectionId: collectionIdConfig = '',\n\t\t\t\t\tmaxEntities: maxFacesConfig = 50,\n\t\t\t\t} = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\t// default arguments\n\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: getAmplifyUserAgent(),\n\t\t});\n\t\tlet inputImage: Image;\n\t\tawait this.configureSource(input.entities.source)\n\t\t\t.then(data => (inputImage = data))\n\t\t\t.catch(err => {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t});\n\n\t\tconst param = { Attributes: ['ALL'], Image: inputImage };\n\n\t\tif (\n\t\t\tisIdentifyCelebrities(input.entities) &&\n\t\t\tinput.entities.celebrityDetection\n\t\t) {\n\t\t\tif (!celebrityDetectionEnabled) {\n\t\t\t\treturn Promise.reject(\n\t\t\t\t\t'Error: You have to enable celebrity detection first'\n\t\t\t\t);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tconst recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(\n\t\t\t\t\tparam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\trecognizeCelebritiesCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.CelebrityFaces.map(celebrity => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t...makeCamelCase(celebrity, ['Id', 'Name', 'Urls']),\n\t\t\t\t\t\t\tpose: makeCamelCase(celebrity.Face.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else if (\n\t\t\tisIdentifyFromCollection(input.entities) &&\n\t\t\tinput.entities.collection\n\t\t) {\n\t\t\tconst {\n\t\t\t\tcollectionId = collectionIdConfig,\n\t\t\t\tmaxEntities: maxFaces = maxFacesConfig,\n\t\t\t} = input.entities as IdentifyFromCollection;\n\t\t\t// Concatenate additional parameters\n\t\t\tconst updatedParam = {\n\t\t\t\t...param,\n\t\t\t\tCollectionId: collectionId,\n\t\t\t\tMaxFaces: maxFaces,\n\t\t\t};\n\t\t\ttry {\n\t\t\t\tconst searchFacesByImageCommand = new SearchFacesByImageCommand(\n\t\t\t\t\tupdatedParam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\tsearchFacesByImageCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.FaceMatches.map(val => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(val.Face.BoundingBox),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\texternalImageId: this.decodeExternalImageId(\n\t\t\t\t\t\t\t\tval.Face.ExternalImageId\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\tsimilarity: val.Similarity,\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tconst detectFacesCommand = new DetectFacesCommand(param);\n\t\t\t\tconst data = await this.rekognitionClient.send(detectFacesCommand);\n\t\t\t\tconst faces = data.FaceDetails.map(detail => {\n\t\t\t\t\t// face attributes keys we want to extract from Rekognition's response\n\t\t\t\t\tconst attributeKeys = [\n\t\t\t\t\t\t'Smile',\n\t\t\t\t\t\t'Eyeglasses',\n\t\t\t\t\t\t'Sunglasses',\n\t\t\t\t\t\t'Gender',\n\t\t\t\t\t\t'Beard',\n\t\t\t\t\t\t'Mustache',\n\t\t\t\t\t\t'EyesOpen',\n\t\t\t\t\t\t'MouthOpen'\n\t\t\t\t\t];\n\t\t\t\t\tconst faceAttributes = makeCamelCase(detail, attributeKeys);\n\t\t\t\t\tif (detail.Emotions) {\n\t\t\t\t\t\tfaceAttributes['emotions'] = detail.Emotions.map(\n\t\t\t\t\t\t\temotion => emotion.Type\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(detail.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(detail.Landmarks),\n\t\t\t\t\t\tageRange: makeCamelCase(detail.AgeRange),\n\t\t\t\t\t\tattributes: faceAttributes,\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\tconfidence: detail.Confidence,\n\t\t\t\t\t\t\tpose: makeCamelCase(detail.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate decodeExternalImageId(externalImageId: string): string {\n\t\treturn ('' + externalImageId).replace(/::/g, '/');\n\t}\n}\n\n/**\n * @deprecated use named import\n */\nexport default AmazonAIIdentifyPredictionsProvider;\n"]},"metadata":{},"sourceType":"module"}